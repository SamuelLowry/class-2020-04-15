---
title: "Chapters 19 and 20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(remotes)     # Cool people no longer use **devtools** for Github installs.
library(janitor)
library(broom)
library(rstanarm)
library(gt)
library(tidyverse)

# Install the latest version with: remotes::install_github("davidkane9/gov.1005.data")
# Provides access to train data

library(gov.1005.data)

# Don't like the factor ordering in the current data. So, switch to character,
# which, because of the default alphabetical ordering, gets me what I want.

train <- train %>% 
  mutate(treatment = as.character(treatment))

```


Recall "Causal effect of intergroup contact on exclusionary attitudes" by Ryan Enos. PNAS March 11, 2014 111 (10) 3699-3704. ([pdf](https://www.pnas.org/content/pnas/111/10/3699.full.pdf%20))). We will explore this data, using the techniques from chapters 19 and 20.


# Scene 1

**Prompt:** Instead of focusing in the change in attitude, which is what Enos does, let's start by looking at the effect of treatment on `att_end`, the persons attitude toward immigration in the final survey, after the experiment is complete. Use  `stan_glm()` to estimate and interpret a model, called `model_1`, in which `att_end` is the dependent variable and `treatment` is the explanatory variable. Provide some intuition about:

```{r}
model_1 <- stan_glm(data = train, att_end ~ treatment, refresh = FALSE)

model_1

summary(model_1)
```

* Why is intercept 8.4?

untreated att_end is 8.4

* Why is treatment effect 1.6?

the treatment, exposure to Spanish speaking confederates, attitude increases by 1.5 meaning more anti-immigration

* Why is sigma 2.8?

sigma is the MAD SD of the residuals

Also, provide a sentence about the 90% confidence interval for the treatment effect with a Bayesian interpreptation.

```{r}

thing <- as.matrix(model_1)

interval <- quantile(thing[, 2], c(0.05, 0.95)) 

interval_tibble <- tibble("5%" = round(interval[1], digits = 3), "95%" = round(interval[2], digits = 3))

interval_tibble %>% 
  gt() %>% 
  tab_header(title = "90% Confidence Interval")
```




# Scene 2

**Prompt:** Create a new model, `model_2`, which is just like `model_1` but which includes `att_start` as an additional regressor. Interpret the associated coefficients. 

```{r}
train <- train %>% 
  mutate(att_start = att_start - mean(att_start))

model_2 <- stan_glm(data = train, att_end ~ treatment + att_start, refresh = FALSE)

model_2
```

* The intercept is now 1.4. Provide an interpretation.



* sigma is now 1.3. Why? What does that mean?

smaller st dv of redisuals! better fit!

* How do the inferences you would draw from `model_1` differ from those you would draw from `model_3`? 

* Which model is the truth?

neither!

# Scene 3

```{r}

model_3 <- stan_glm(data = train, att_end ~ treatment + att_start + male + treatment*male, refresh = FALSE)

model_3
```

**Prompt:** Let's consider interactions. Create a new model, `model_3`, which is just like `model_1` but which includes `att_start`, `male`, `treatment` and the interaction between `male` and `treatment` as regressors. Interpret the associated coefficients. Is the treatment effect different for men?

Imagine we one man and one women, both with `att_start = 9`. We are interested in two things.

First, what is the unobservable predictor for the true att_end for each person if given treatment. Hint: `posterior_linpred()`. What is the 95% confidence interval?

```{r}
newdata <- tibble(treatment = c("Treated", "Treated"),
                  male = c(1, 0),
                  att_start = c(9, 9))

#predictor
#likelyhood uses transform = FALSE
#probability uses transform = TRUE

pred <- posterior_linpred(model_3, transform = FALSE, newdata = newdata)

#posterior predict includes much more uncertainty
```


Second, if we give expose them to the treatment, what will their `att_end` be? Hint: `posterior_predict()`. What is a 95% confidence interval for this forecast?


# Scene 4

**Prompt:** Enos does not estimate this model. Instead, he uses a model with `att_chg` as the outcome variable. Use  `stan_glm()` to estimate and interpret a model, called `model_4`, in which `att_chg` is the dependent variable and `treatment` is the explanatory variable.

How does the estimated treatment effect differ between `model_1` and `model_4`? What causes that difference? Which one is correct?

```{r}
model_4 <- stan_glm(data = train, att_chg ~ treatment, refresh = FALSE)

model_4
```



# Scene 5


**Prompt:** Create a tibble, called `scene_5`, which creates the same model as in Scene 1, but for four sub-groups separately: combinations of male/female and Republican/Non-Republican. Before running the regression, what do you predict you will find? Will the treatment effect vary across these groupings? Why?

Hints: You want to create a new variable which defines your four blocks, then `nest` with that variable. The *Primer* provides some useful examples.

After running the analysis, interpret the intercept and coefficient estimates across the models. Do they match your predictions? Is there evidence of varying treatment effects?

It seems that the treatment only has an effect on two of the four sub-groups. Tell me a story about why that might be the case.



# Challenge Problems

Make a cool animation with the train data, using [this package](https://github.com/daranzolin/d3rain). Start with someone's starting attitude, then they either get treatment or control, and then they end up with their ending attitude. Animate the people as dots, moving (on a train!?) from where they start to where they finish.



# Final Projects

**Prompt:** Go to the joint repo for final projects: https://github.com/GOV-1006-Spring-2020/papers. We will spend 20 minutes on this. Each person gets 20/N minutes. Allow everyone to read your abstract. Each person must then make a comment or suggestion on the abstract. Exact word choice matters. Refer to our guidance. (Version 2 distributed at the start of class.) Then, open your PDF. Give a brief tour. Talk about your extension. Get some feedback.

